Original Article
Prediction of radiographic abnormalities by the use of bag-of-features
and convolutional neural networks
Y. Yoon, T. Hwang, H. Lee*
Institute of Animal Medicine, College of Veterinary Medicine, Gyeongsang National University, Jinju 30488, South Korea
A R T I C L E I N F O
Article history:
Accepted 25 May 2018
Keywords:
Computer aided detection
Convolutional neural networks
Dog
Machine learning
Thoracic radiography
A B S T R A C T
This study evaluated the feasibility of bag-of-features (BOF) and convolutional neural networks (CNN) for
computer-aided detection in distinguishing normal from abnormal radiographic ﬁndings. Computed
thoracic radiographs of dogs were collected. For the purposes of this study, radiographic ﬁndings were
used to distinguish between normal and abnormal in the following areas: (1) normal cardiac silhouette
vs. cardiomegaly, (2) normal lung vs. abnormal lung patterns, (3) normal mediastinal position vs.
mediastinal shift, (4) normal pleural space vs. pleural effusion, and (5) normal pleural space vs.
pneumothorax. Images for training and testing the models consisted of ventrodorsal and lateral
projection images of the same scale. The number of images used for each ﬁnding are as follow: 3142 for
cardiomegaly (1571 normal and 1571 abnormal from 1143 dogs), 2086 for lung pattern (1043 normal and
1043 abnormal from 1247 dogs), 892 for mediastinal shift (446 normal and 446 abnormal from 387 dogs),
940 for pleural effusion (470 normal and 470 abnormal from 284 dogs), and 78 for pneumothorax (39
normal and 39 abnormal from 61 dogs). All data samples were divided so that 60% would be used for
training the algorithms and 40% for testing the two models. The performance of the classiﬁers was
evaluated by calculating the accuracy, sensitivity and speciﬁcity.
The accuracy of both models ranged from 79.6% to 96.9% in the testing set. CNN showed higher accuracy

training data is important in this process because supervisor’s
subjective standards can inﬂuence the ROI, the method for feature
extraction and selection, and ultimately the performance of
the CAD.
Machine learning is the study that constructs algorithms which
can learn from and make predictions on data. Artiﬁcial neural
networks, a set of well established machine learning algorithms,
are models that solve problems and represent information in a way
analogous to that of a human brain (Baxt, 1991; Sujana et al., 1996).
A basic operating unit in artiﬁcial neural networks is a neuron-like
node. Each connection between nodes can transmit numbers from
* Corresponding author.
E-mail address: lhc@gnu.ac.kr (H. Lee).
https://doi.org/10.1016/j.tvjl.2018.05.009
1090-0233/© 2018 Elsevier Ltd. All rights reserved.
The Veterinary Journal 237 (2018) 43– 48
Contents lists available at ScienceDirect
The Veterinary Journal
journal  homepage:  www.else  vie  r.com/locate  /t vjl

amount of clinical clue within a small number of images. Thoracic
radiography, in particular, shows many conditions involving the
mediastinum, heart, trachea, lungs, and pleura. We also chose
thoracicradiography for this study, becauseit iswidely usedandthus
a large number of data images could be accumulated.
Previous CAD studies focused on the detection of diseases based
on a speciﬁc radiological ﬁnding (Kadah et al., 1996; Sujana et al.,
1996; Chen et al., 1998; Chen et al., 2013). An appropriate diagnosis
may be made by considering additional radiological ﬁndings and
non-radiological ﬁndings. In addition, non-radiological ﬁndings
cannot be incorporated into the structure of a BOF or CNN.
Therefore, the goal of this study was aimed at detecting abnormal
radiographic ﬁndings.
Feature detection methods commonly used in the BOF
algorithm are scale-invariant feature transformation (SIFT) and
SURF (Lowe, 1999; Bay et al., 2008). SIFT is invariant to image
translation, scaling, and rotation, partially invariant to illumination
changes and robust to local geometric distortion (Lowe, 1999).
SURF, while partly inspired by SIFT, is several times faster and is
thought to be more robust against different image transformations
than SIFT (Bay et al., 2008); for these reasons, we chose SURF as the
feature detector. The detail settings of the BOF algorithm were
determined at the highest performance level through trial and
error. With this setting, the BOF model showed excellent
performance in the classiﬁcation of cardiomegaly, pleural effusion,
and pneumothorax in the testing set.
Fig. 2. Schematic diagram of detailed conﬁguration and processing of BOF. (A) Feature extraction. Speed-up robust features (SURF) was used to extract features. Local patches
were created using 4 /C2 4 grid. The patches were extracted as numerical vectors (features) by using multiple blocks (block width 32, 48, 64, 80, and 96). Eighty percent of

Barcelona, Spain, July 2011.
Csurka, G., Dance, C., Fan, L., Willamowski, J., Bray, C., 2004. Visual categorization
with bags of keypoints. Workshop on Statistical Learning in Computer Vision,
ECCV, Praque, Czech Republic, 10th– 16th May 2004.
Escalera, S., Pujol, O., Radeva, P., 2010. Error-correcting output codes library. Journal
of Machine Learning Research 11, 661– 664.
Fei-Fei, L., Perona, P., 2005. A bayesian hierarchical model for learning natural scene
categories. IEEE Computer Society Conference on Computer Vision and Pattern
Recognition, San Diego, California, USA, 20th– 25th June 2005.
Jiang, M., Zhang, S., Li, H., Metaxas, D.N., 2015. Computer-aided diagnosis of
mammographic masses using scalable image retrieval. IEEE Transactions on
Biomedical Engineering 62, 783– 792.
Kadah, Y.M., Farag, A.A., Zurada, J.M., Badawi, A.M., Youssef, A.-B., 1996.
Classiﬁcation algorithms for quantitative tissue characterization of diffuse liver
disease from ultrasound images. IEEE Transactions on Medical Imaging 15, 466–
478.
Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. Imagenet classiﬁcation with deep
convolutional neural networks. Advances in Neural Information Processing
Systems, Lake tahoe, Nevada, USA, 3rd– 8th December 2012.
Lowe, D.G., 1999. Object recognition from local scale-invariant features. The
Proceedings of the Seventh IEEE International Conference on Computer Vision,
Kerkyra, Greece, 20th– 27th September 1999.
Malon, C.D., Cosatto, E., 2013. Classiﬁcation of mitotic ﬁgures with convolutional
neural networks and seeded blob features. Journal of Pathology Informatics 4, 9.
McEvoy, F.J., Amigo, J.M., 2013. Using machine learning to classify image features
from canine pelvic radiographs: evaluation of partial least squares discriminant
analysis and artiﬁcial neural network models. Veterinary Radiology &
Ultrasound 54, 122– 126.
Murphy, K.P., 2012. Machine Learning: A Probabilistic Perspective. MIT Press.

critical information thereby improving the ability to generalize.
Local connectivity and weight-sharing between layers then allows
for training of the networks. BOF and CNN can both extract and
learn the features of images and thereby classify the images
(Csurka et al., 2004; Yang et al., 2009; Ciresan et al., 2011;
Krizhevsky et al., 2012). This suggests that both BOF and CNN can
be used for radiologic interpretation.
In this study, the goal was to discriminate normal vs. abnormal
radiographic ﬁndings using BOF and CNN and to evaluate their
performance.
Materials and methods
A computer with Microsoft Windows 10 (64 bit), an Intel Core i7 4.9 gigahertz
central processing unit, 32 gigabyte random-access memory, and a NVIDIA Quadro
M4000 graphics card was used for this study. The algorithms for image acquisition
and machine learning were coded in MATLAB (R2016b, MathWorks). The toolboxes
used in MATLAB were computer vision system, curve ﬁtting, data acquisition, global
optimization, image acquisition, image processing, neural network, optimization,
parallel computing, and statistics and machine learning.
Computed thoracic radiographs with normal and abnormal radiographic
ﬁndings from dogs were collected retrospectively from a database at the Veterinary
Medical Teaching Hospital of Gyeongsang National University from 2012 to 2016. A
direct digitizer Regius190 (Konica Minolta) was used to image radiographs (50–
70 kVp, 300 mA, and 6.0 mAs). Three veterinary radiologists (one veterinary
radiology Ph.D. and two veterinary radiology masters) evaluate the radiographs
individually, and the radiographs were excluded if there was a disagreement in
individual interpretations. Images with inappropriate posture or severe rotation
were excluded. Based on subjective interpretations of the radiographs (Table 1),
each image was classiﬁed as being normal or abnormal with regard to ﬁve speciﬁc
ﬁndings: (1) normal cardiac silhouette vs. cardiomegaly, (2) normal lung vs.

the models were scarce; to avoid an imbalance (Seiffert et al.,
2008), many normal data images had to be discarded to ﬁt the
number of abnormal images. More data images or ways to
overcome problems caused by imbalanced data are needed to
achieve more reliable results. In this study, the radiographs were
excluded if there was a disagreement among the radiologists, in
order to design algorithms that detect obvious ﬁndings, and to
minimize the false negative rate of the radiologists. Therefore, the
tendency of this data might make the algorithms easier to classify.
For more clear validation, a sufﬁcient data image of unclear
ﬁndings may be needed. The algorithms used the image that was
the largest possible size for computation because the system
speciﬁcations were limited, and the pilot study using smaller
images showed lower performance in each of the BOF and CNN. It is
difﬁcult to determine whether the larger image will lead to better
performance or the size used in this study is most appropriate.
Further research is needed to determine if larger images can
provide an increased accuracy, but a more powerful computer will
be needed to allow this information to be provided in a clinically
useful timeframe. The images used in both algorithms were not the
same size. Although the BOF showed lower performance than the
CNN at the same size in the pilot study, it might not be the
optimum setting. Further research may be required.
Conclusions
This study compares the performance of two predictive machine
learning algorithms that classify ﬁve speciﬁc conditions as being
normal or abnormal, including cardiomegaly, lung patterns,
mediastinal shift, pleural effusion, and pneumothorax. Although
all of the data was acquired from one device and some of the ﬁndings
did not have a signiﬁcant volume of data, the classiﬁers demonstrat-
ed high accuracy. These algorithms may potentially be useful for
improving work efﬁciency by double reading.
Conﬂict of interest statement

evaluated by calculating the accuracy, sensitivity and speciﬁcity.
The accuracy of both models ranged from 79.6% to 96.9% in the testing set. CNN showed higher accuracy
(CNN; 92.9– 96.9% and BOF; 79.6– 96.9%) and sensitivity (CNN; 92.1– 100% and BOF; 74.1– 94.8%) than BOF.
In conclusion, both BOF and CNN have potential to be useful for improving work efﬁciency by double
reading.
© 2018 Elsevier Ltd. All rights reserved.
Introduction
Computers are used in diagnostic imaging for image acquisi-
tion, management, storage, and reporting. Computer algorithms
have also been developed and used in human clinical practice for
what is commonly called computer-aided detection (CAD). CAD is a
technology combining elements of machine learning and comput-
er vision with medical imaging. The primary goal of CAD is to
support the detection of disease and provide a consistent and
reproducible second opinion for clinicians. This strategy of double
reading can potentially improve workﬂow efﬁciency by reducing
the rate of false negatives due to observational oversights
(Castellino, 2005; Jiang et al., 2015; AlZubaidi et al., 2017). Previous
CAD studies focused on the differentiation of diseases (Kadah et al.,
1996; Sujana et al., 1996; Chen et al., 1998; Chen et al., 2013). These
CAD algorithms usually detected the disease based on a speciﬁc
radiological ﬁnding.
Most studies of CAD include the following steps: cropping the
region of interest (ROI) from the medical image, extracting features
from the ROI, selecting features, training algorithms using the
features, and making predictions using the training algorithms
(Baxt, 1991; Chen et al., 1998; Vlahou et al., 2003; Polat and Güneş,
2007; Akay, 2009; Malon and Cosatto, 2013; Roth et al., 2014;
Wang et al., 2014). The role of the supervisor who labels the class of
training data is important in this process because supervisor’s
subjective standards can inﬂuence the ROI, the method for feature

ed high accuracy. These algorithms may potentially be useful for
improving work efﬁciency by double reading.
Conﬂict of interest statement
None of the authors of this paper have a ﬁnancial or personal
relationship with other people or organizations that could
inappropriately inﬂuence or bias the content of the paper.
References
Akay, M.F., 2009. Support vector machines combined with feature selection for
breast cancer diagnosis. Expert Systems with Applications 36, 3240– 3247.
AlZubaidi, A.K., Sideseq, F.B., Faeq, A., Basil, M., 2017. Computer aided diagnosis in
digital pathology application: review and perspective approach in lung cancer
classiﬁcation. New Trends in Information & Communications Technology
Applications 219– 224.
Baxt, W.G., 1991. Use of an artiﬁcial neural network for the diagnosis of myocardial
infarction. Annals of Internal Medicine 115, 843– 848.
Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., 2008. Speeded-up robust features (SURF).
Computer Vision and Image Understanding 110, 346– 359.
Castellino, R.A., 2005. Computer aided detection (CAD): an overview. Cancer
Imaging 5, 17.
Chen, E.L., Chung, P.C., Chen, C.L., Tsai, H.M., Chang, C.I., 1998. An automatic
diagnostic system for CT liver image classiﬁcation. IEEE Transactions on
Biomedical Engineering 45, 783– 794.
Chen, H.L., Huang, C.C., Yu, X.G., Xu, X., Sun, X., Wang, G., Wang, S.J., 2013. An efﬁcient
diagnosis system for detection of Parkinson’s disease using fuzzy k-nearest
neighbor approach. Expert Systems with Applications 40, 263– 271.
Ciresan, D.C., Meier, U., Masci, J., Maria, G.L., Schmidhuber, J., 2011. Flexible, high
performance convolutional neural networks for image classiﬁcation.
Proceedings of International Joint Conference on Artiﬁcial Intelligence,
Barcelona, Spain, July 2011.
Csurka, G., Dance, C., Fan, L., Willamowski, J., Bray, C., 2004. Visual categorization
with bags of keypoints. Workshop on Statistical Learning in Computer Vision,

were created using 4 /C2 4 grid. The patches were extracted as numerical vectors (features) by using multiple blocks (block width 32, 48, 64, 80, and 96). Eighty percent of
strongest features were preserved. The features were deﬁned as visual words by clustering similar patches (k = 1500). (B) Codebook generation. Based on the occurrence of
visual words, histogram (codebook) is generated. (C and D) Binary support vector machine was trained using the codebook, and matched the histogram to predict categories
of general untrained images.
Fig. 3. Schematic diagram of detailed conﬁguration and processing of convolutional neural networks. Maximum epoch (MaxE), one iteration of stochastic gradient descent
(SGD), was 2000. Mini-batch size (MBS), a subset of data during one iteration, was 30. Convolutional layers (CONV) applied various ﬁlters to output multi-channel data (12
ﬁlters with 5 /C2 5 sizes and 16 ﬁlters with 3 /C2 3 sizes). Rectiﬁed linear unit layers (ReLU) determined the degree of activation of the input value. Channel-wise local response
normalization layers (NORM) put the input values on the same scale. Max pooling layers (MaxP) reduced the number of parameters by selecting the maximum value within
the 2 /C2 2 sizes. Fully connected layers (FullC) multiplied the input by a weight matrix and then added a bias vector. The ﬁrst FullC output 256 parameters, the second FullC
output 16 parameters, and the last FullC output 2 parameters. Drop out layer (DropO) randomly set the input elements to zero with a probability of 0.5. Softmax layer (SoftM)
took as input a number of scores values and squashed them into values in the range between 0 and 1 whose sum is 1. SGD tried to ﬁnd minima or maxima by iteration with L2
regularizer (L2R).
46 Y. Yoon et al. / The Veterinary Journal 237 (2018) 43–48

analysis and artiﬁcial neural network models. Veterinary Radiology &
Ultrasound 54, 122– 126.
Murphy, K.P., 2012. Machine Learning: A Probabilistic Perspective. MIT Press.
Polat, K., Güneş, S., 2007. Breast cancer diagnosis using least square support vector
machine. Digital Signal Processing 17, 694– 701.
Table 3
Performance of bag-of-features and convolutional neural networks. The perfor-
mance differences between training and testing data for each ﬁnding were small.
Accuracy (%) Sensitivity (%) Speciﬁcity (%)
BOF CNN BOF CNN BOF CNN
Train CM 91.9 99.7 90.6 99.9 93.3 99.6
LP 83.9 99.8 79.6 99.8 88.3 99.7
MS 93.1 100.0 91.8 100.0 94.4 100.0
PE 96.6 99.5 94.7 100.0 98.6 99.6
PT 97.8 100.0 95.7 100.0 100.0 100.0
Test CM 90.9 96.5 90.3 97.0 91.6 96.0
LP 79.6 92.9 74.1 92.1 85.1 93.8
MS 86.8 94.7 84.3 95.5 89.3 93.8
PE 95.2 95.5 91.5 95.7 98.9 95.2
PT 96.9 96.9 93.8 100.0 100.0 93.8
CM, cardiomegaly; LP, abnormal lung pattern; MS, mediastinal shift; PE, pleural
effusion; PT, pneumothorax; BOF, bag-of-features; CNN, convolutional neural
networks.
Y. Yoon et al. / The Veterinary Journal 237 (2018) 43–48 47

